{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/X_train.csv\")\n",
    "data = data.sample(frac=0.02)\n",
    "# data = data[data['Summary'].notna()]\n",
    "data = data[data['Text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Id                                               Text\n",
       "59409      71960  Sorry, but I have to agree with a previous rev...\n",
       "471301    572612  So bad I tried to sell it to blockbuster today...\n",
       "452358    549599  this movie was awful, nothing like the first m...\n",
       "1136165  1380532  127 HOURSSTARRING: James Franco, Kate Mara, Am...\n",
       "872044   1059653  I was caught off guard by how interesting the ...\n",
       "...          ...                                                ...\n",
       "533109    647734  This movie works on several levels.As a semi-d...\n",
       "1038346  1261701  without all of the fancy CGI, and other modern...\n",
       "620049    753402  Probably the single most important reason that...\n",
       "559502    679879  While Queer As Folk is fascinating in that it ...\n",
       "1147469  1394281  This is a good love story that I could watch o...\n",
       "\n",
       "[27949 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>59409</th>\n      <td>71960</td>\n      <td>Sorry, but I have to agree with a previous rev...</td>\n    </tr>\n    <tr>\n      <th>471301</th>\n      <td>572612</td>\n      <td>So bad I tried to sell it to blockbuster today...</td>\n    </tr>\n    <tr>\n      <th>452358</th>\n      <td>549599</td>\n      <td>this movie was awful, nothing like the first m...</td>\n    </tr>\n    <tr>\n      <th>1136165</th>\n      <td>1380532</td>\n      <td>127 HOURSSTARRING: James Franco, Kate Mara, Am...</td>\n    </tr>\n    <tr>\n      <th>872044</th>\n      <td>1059653</td>\n      <td>I was caught off guard by how interesting the ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>533109</th>\n      <td>647734</td>\n      <td>This movie works on several levels.As a semi-d...</td>\n    </tr>\n    <tr>\n      <th>1038346</th>\n      <td>1261701</td>\n      <td>without all of the fancy CGI, and other modern...</td>\n    </tr>\n    <tr>\n      <th>620049</th>\n      <td>753402</td>\n      <td>Probably the single most important reason that...</td>\n    </tr>\n    <tr>\n      <th>559502</th>\n      <td>679879</td>\n      <td>While Queer As Folk is fascinating in that it ...</td>\n    </tr>\n    <tr>\n      <th>1147469</th>\n      <td>1394281</td>\n      <td>This is a good love story that I could watch o...</td>\n    </tr>\n  </tbody>\n</table>\n<p>27949 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "X = data[['Id', 'Text']]\n",
    "Y = data['Score']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    lower_text = text.lower()\n",
    "    tokenized_text = word_tokenize(lower_text)\n",
    "    tok_text_no_punc = [word for word in tokenized_text if word.isalpha()]\n",
    "    tok_text_no_stop = [word for word in tok_text_no_punc if not word in stopwords.words('english')]\n",
    "    return tok_text_no_stop\n",
    "    \n",
    "def text_process_fast(reviewText):\n",
    "    nopunc = [i for i in reviewText if i not in string.punctuation]\n",
    "    nopunc_text = ''.join(nopunc)\n",
    "    return [i for i in nopunc_text.split() if i.lower() not in stopwords.words('english')]\n",
    "\n",
    "def tokenizer(text):\n",
    "    return [word for word in word_tokenize(text) if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['bad',\n",
       " 'tried',\n",
       " 'sell',\n",
       " 'blockbuster',\n",
       " 'today',\n",
       " 'didnt',\n",
       " 'even',\n",
       " 'come',\n",
       " 'system',\n",
       " 'complete',\n",
       " 'waste',\n",
       " 'money']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "text_process(X['Text'].to_numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer(analyzer=text_process, max_features=2000)\n",
    "# vocab = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, lowercase=True, stop_words='english', max_features=21000)\n",
    "svc = SVC(C=0.85, class_weight='balanced', gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing tf-idf, total=  22.2s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 8.0min\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf-idf',\n",
       "                 TfidfVectorizer(max_features=21000, stop_words='english',\n",
       "                                 tokenizer=<function tokenizer at 0x000001C4FADDFB80>)),\n",
       "                ('classifier', SVC(C=0.85, class_weight='balanced'))],\n",
       "         verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "pipeline = Pipeline([('tf-idf', tfidf), ('classifier', svc)], verbose=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.15)\n",
    "pipeline.fit(x_train['Text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionSet = pd.read_csv(\"./data/prediction.csv\")\n",
    "# predictionSet = predictionSet[predictionSet['Summary'].notnull()]\n",
    "predictionSet['Text'].fillna(\"na\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = predictionSet['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionSet['Score'] = pipeline.predict(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Id                                               Text  Score\n",
       "93           110  Joseph is amazing story to read and watch.  A ...    5.0\n",
       "437          512  This is a very basic cooking dvd, which I thin...    4.0\n",
       "652          786  I love this movie...It has a real sactifying e...    5.0\n",
       "1325        1613  i'm a fan of olivia dehaviland.  she is a wond...    5.0\n",
       "2187        2644  If you are reading this, you're already famili...    5.0\n",
       "...          ...                                                ...    ...\n",
       "1396306  1696034  I watched this movie in the theatre and was ve...    4.0\n",
       "1396345  1696081  Comedy?  Spy thriller?  One thing is for sure,...    5.0\n",
       "1396758  1696584  This film can't decide whether it wants to be ...    3.0\n",
       "1397049  1696946  I loved this little movie and I think you will...    4.0\n",
       "1397086  1696994  Cause I'm really wanting to dig this, however ...    5.0\n",
       "\n",
       "[4193 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Text</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>93</th>\n      <td>110</td>\n      <td>Joseph is amazing story to read and watch.  A ...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>437</th>\n      <td>512</td>\n      <td>This is a very basic cooking dvd, which I thin...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>652</th>\n      <td>786</td>\n      <td>I love this movie...It has a real sactifying e...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1325</th>\n      <td>1613</td>\n      <td>i'm a fan of olivia dehaviland.  she is a wond...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2187</th>\n      <td>2644</td>\n      <td>If you are reading this, you're already famili...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1396306</th>\n      <td>1696034</td>\n      <td>I watched this movie in the theatre and was ve...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1396345</th>\n      <td>1696081</td>\n      <td>Comedy?  Spy thriller?  One thing is for sure,...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1396758</th>\n      <td>1696584</td>\n      <td>This film can't decide whether it wants to be ...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1397049</th>\n      <td>1696946</td>\n      <td>I loved this little movie and I think you will...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1397086</th>\n      <td>1696994</td>\n      <td>Cause I'm really wanting to dig this, however ...</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4193 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "x_test['Score'] = pipeline.predict(x_test['Text'])\n",
    "x_test = x_test.sort_values(by=['Id'])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Id  Score\n0   5    5.0\n1  11    4.0\n2  17    4.0\n3  46    5.0\n4  47    2.0\n"
     ]
    }
   ],
   "source": [
    "submission = predictionSet[['Id', 'Score']]\n",
    "submission_offline = x_test[['Id', 'Score']]\n",
    "print(submission.head())\n",
    "submission.to_csv(\"./data/submission_fast.csv\", index=False)\n",
    "submission_offline.to_csv(\"./data/submission_offline_fast.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}