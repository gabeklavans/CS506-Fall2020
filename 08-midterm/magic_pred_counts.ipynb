{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/X_train.csv\")\n",
    "data = data.sample(frac=0.006)\n",
    "# data = data[data['Summary'].notna()]\n",
    "data = data[data['Text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Id                                               Text\n",
       "1173575  1426079  Countless specials have been made on dinosaurs...\n",
       "153915    186828  Enjoyed the film! Complicated story. We are cu...\n",
       "486238    590709  ...A BEAUTIFUL MIND is really a fine film, wel...\n",
       "182260    221240  I've seen the Godfather trilogy many times ove...\n",
       "792364    962922  It's tough to fathom a G-rated animated film g...\n",
       "...          ...                                                ...\n",
       "397737    483189  Seeing the R-Rated DVD version of SUPERNOVA ma...\n",
       "1127361  1369936  THE ROAD TO CHRISTMAS IS A VERY MOVING FAMILY ...\n",
       "961453   1168340  From the title \"Dog Tags,\" and the \"come hithe...\n",
       "1087883  1321937  This movie was pretty good. The only troubling...\n",
       "1240687  1507307  The next season, after they kill several of th...\n",
       "\n",
       "[8384 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1173575</th>\n      <td>1426079</td>\n      <td>Countless specials have been made on dinosaurs...</td>\n    </tr>\n    <tr>\n      <th>153915</th>\n      <td>186828</td>\n      <td>Enjoyed the film! Complicated story. We are cu...</td>\n    </tr>\n    <tr>\n      <th>486238</th>\n      <td>590709</td>\n      <td>...A BEAUTIFUL MIND is really a fine film, wel...</td>\n    </tr>\n    <tr>\n      <th>182260</th>\n      <td>221240</td>\n      <td>I've seen the Godfather trilogy many times ove...</td>\n    </tr>\n    <tr>\n      <th>792364</th>\n      <td>962922</td>\n      <td>It's tough to fathom a G-rated animated film g...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>397737</th>\n      <td>483189</td>\n      <td>Seeing the R-Rated DVD version of SUPERNOVA ma...</td>\n    </tr>\n    <tr>\n      <th>1127361</th>\n      <td>1369936</td>\n      <td>THE ROAD TO CHRISTMAS IS A VERY MOVING FAMILY ...</td>\n    </tr>\n    <tr>\n      <th>961453</th>\n      <td>1168340</td>\n      <td>From the title \"Dog Tags,\" and the \"come hithe...</td>\n    </tr>\n    <tr>\n      <th>1087883</th>\n      <td>1321937</td>\n      <td>This movie was pretty good. The only troubling...</td>\n    </tr>\n    <tr>\n      <th>1240687</th>\n      <td>1507307</td>\n      <td>The next season, after they kill several of th...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8384 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "X = data[['Id', 'Text']]\n",
    "Y = data['Score']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    lower_text = text.lower()\n",
    "    tokenized_text = word_tokenize(lower_text)\n",
    "    tok_text_no_punc = [word for word in tokenized_text if word.isalpha()]\n",
    "    tok_text_no_stop = [word for word in tok_text_no_punc if not word in stopwords.words('english')]\n",
    "    return tok_text_no_stop\n",
    "    \n",
    "def text_process_fast(reviewText):\n",
    "    nopunc = [i for i in reviewText if i not in string.punctuation]\n",
    "    nopunc_text = ''.join(nopunc)\n",
    "    return [i for i in nopunc_text.split() if i.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['enjoyed',\n",
       " 'film',\n",
       " 'complicated',\n",
       " 'story',\n",
       " 'currently',\n",
       " 'living',\n",
       " 'germany',\n",
       " 'reason',\n",
       " 'fascinated',\n",
       " 'whole',\n",
       " 'ludwig',\n",
       " 'story',\n",
       " 'great',\n",
       " 'job']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "text_process(X['Text'].to_numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer(analyzer=text_process, max_features=2000)\n",
    "# vocab = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing Tf-idf, total= 3.5min\n[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.0s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tf-idf',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x0000019B7605BA60>)),\n",
       "                ('classifier', MultinomialNB())],\n",
       "         verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tf-idf', CountVectorizer(analyzer=text_process)), ('classifier', MultinomialNB())], verbose=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "pipeline.fit(x_train['Text'], y_train)\n",
    "# prediction = pipeline.predict(x_test)\n",
    "# metrics.classification_report(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionSet = pd.read_csv(\"./data/prediction.csv\")\n",
    "# predictionSet = predictionSet[predictionSet['Summary'].notnull()]\n",
    "predictionSet['Text'].fillna(\"na\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = predictionSet['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Id                                               Text  Score\n",
       "117          136  This is an accurate and realistic depiction of...    5.0\n",
       "390          456  If there was ever a show on T.V. that could pu...    5.0\n",
       "1734        2109  I saw this film many years ago and it left an ...    4.0\n",
       "2119        2561  I bought this VHS movie because it brought bac...    5.0\n",
       "5446        6568  Loved it....True pure SCIFY...at its best........    5.0\n",
       "...          ...                                                ...    ...\n",
       "1389274  1687472  I don't know how Hollywood found all my uncles...    5.0\n",
       "1391623  1690307  Cute movie for kids; blot was ok, not the best...    5.0\n",
       "1392281  1691120  Although a little slower in the beginning whil...    5.0\n",
       "1393562  1692669  I had the good fortune of hearing Kate Mulgrew...    5.0\n",
       "1396424  1696180  When the movie started the opening scenes, I t...    5.0\n",
       "\n",
       "[839 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Text</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>117</th>\n      <td>136</td>\n      <td>This is an accurate and realistic depiction of...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>456</td>\n      <td>If there was ever a show on T.V. that could pu...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1734</th>\n      <td>2109</td>\n      <td>I saw this film many years ago and it left an ...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2119</th>\n      <td>2561</td>\n      <td>I bought this VHS movie because it brought bac...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>5446</th>\n      <td>6568</td>\n      <td>Loved it....True pure SCIFY...at its best........</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1389274</th>\n      <td>1687472</td>\n      <td>I don't know how Hollywood found all my uncles...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1391623</th>\n      <td>1690307</td>\n      <td>Cute movie for kids; blot was ok, not the best...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1392281</th>\n      <td>1691120</td>\n      <td>Although a little slower in the beginning whil...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1393562</th>\n      <td>1692669</td>\n      <td>I had the good fortune of hearing Kate Mulgrew...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1396424</th>\n      <td>1696180</td>\n      <td>When the movie started the opening scenes, I t...</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>839 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# predictionSet['Score'] = pipeline.predict(x_predict)\n",
    "x_test['Score'] = pipeline.predict(x_test['Text'])\n",
    "x_test = x_test.sort_values(by=['Id'])\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        Id  Score\n117    136    5.0\n390    456    5.0\n1734  2109    4.0\n2119  2561    5.0\n5446  6568    5.0\n"
     ]
    }
   ],
   "source": [
    "# submission = predictionSet[['Id', 'Score']]\n",
    "submission_offline = x_test[['Id', 'Score']]\n",
    "print(submission_offline.head())\n",
    "# submission.to_csv(\"./data/submission.csv\", index=False)\n",
    "submission_offline.to_csv(\"./data/submission_offline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}