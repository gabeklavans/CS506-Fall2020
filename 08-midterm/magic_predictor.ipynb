{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/X_train.csv\")\n",
    "data = data.sample(frac=0.015)\n",
    "# data = data[data['Summary'].notna()]\n",
    "data = data[data['Text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Id                                               Text\n",
       "22573      27293  Ambitious dancer uses the horny goat leader of...\n",
       "635987    772828  Currently everybody thinks of him as directing...\n",
       "1098855  1335223  Beth (Kristen Bell) is a N.Y. curator who take...\n",
       "968490   1176851  Rob Halford (aka The Metal God) and his bandma...\n",
       "995135   1209158  yeah so what am i going to say you don't alrea...\n",
       "...          ...                                                ...\n",
       "64811      78614  I'm not going to waste time on the story of Ci...\n",
       "437926    532004  This was a great movie! My dad was in the Navy...\n",
       "399347    485138  I love how Jim Jarmusch lets the viewer decide...\n",
       "628862    764126  I had forgotten about this series. It wasn't o...\n",
       "486265    590748  This is a true story. Ron Howard did a superb ...\n",
       "\n",
       "[20963 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22573</th>\n      <td>27293</td>\n      <td>Ambitious dancer uses the horny goat leader of...</td>\n    </tr>\n    <tr>\n      <th>635987</th>\n      <td>772828</td>\n      <td>Currently everybody thinks of him as directing...</td>\n    </tr>\n    <tr>\n      <th>1098855</th>\n      <td>1335223</td>\n      <td>Beth (Kristen Bell) is a N.Y. curator who take...</td>\n    </tr>\n    <tr>\n      <th>968490</th>\n      <td>1176851</td>\n      <td>Rob Halford (aka The Metal God) and his bandma...</td>\n    </tr>\n    <tr>\n      <th>995135</th>\n      <td>1209158</td>\n      <td>yeah so what am i going to say you don't alrea...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>64811</th>\n      <td>78614</td>\n      <td>I'm not going to waste time on the story of Ci...</td>\n    </tr>\n    <tr>\n      <th>437926</th>\n      <td>532004</td>\n      <td>This was a great movie! My dad was in the Navy...</td>\n    </tr>\n    <tr>\n      <th>399347</th>\n      <td>485138</td>\n      <td>I love how Jim Jarmusch lets the viewer decide...</td>\n    </tr>\n    <tr>\n      <th>628862</th>\n      <td>764126</td>\n      <td>I had forgotten about this series. It wasn't o...</td>\n    </tr>\n    <tr>\n      <th>486265</th>\n      <td>590748</td>\n      <td>This is a true story. Ron Howard did a superb ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>20963 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "X = data[['Id', 'Text']]\n",
    "Y = data['Score']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    lower_text = text.lower()\n",
    "    tokenized_text = word_tokenize(lower_text)\n",
    "    tok_text_no_punc = [word for word in tokenized_text if word.isalpha()]\n",
    "    tok_text_no_stop = [word for word in tok_text_no_punc if not word in stopwords.words('english')]\n",
    "    return tok_text_no_stop\n",
    "    \n",
    "def text_process_fast(reviewText):\n",
    "    nopunc = [i for i in reviewText if i not in string.punctuation]\n",
    "    nopunc_text = ''.join(nopunc)\n",
    "    return [i for i in nopunc_text.split() if i.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['currently',\n",
       " 'everybody',\n",
       " 'thinks',\n",
       " 'directingpan',\n",
       " 'labyrinthor',\n",
       " 'thehellboymovies',\n",
       " 'beginning',\n",
       " 'career',\n",
       " 'guillermo',\n",
       " 'del',\n",
       " 'toro',\n",
       " 'honed',\n",
       " 'directorial',\n",
       " 'skills',\n",
       " 'truly',\n",
       " 'brilliant',\n",
       " 'unique',\n",
       " 'movie',\n",
       " 'called',\n",
       " 'cronos',\n",
       " 'expertly',\n",
       " 'blended',\n",
       " 'alchemy',\n",
       " 'vampirism',\n",
       " 'creeping',\n",
       " 'psychological',\n",
       " 'dealer',\n",
       " 'jes',\n",
       " 'uacute',\n",
       " 'gris',\n",
       " 'federico',\n",
       " 'luppi',\n",
       " 'handling',\n",
       " 'angel',\n",
       " 'statue',\n",
       " 'finds',\n",
       " 'insectile',\n",
       " 'metal',\n",
       " 'object',\n",
       " 'bottom',\n",
       " 'bites',\n",
       " 'injecting',\n",
       " 'strange',\n",
       " 'fluid',\n",
       " 'soon',\n",
       " 'jes',\n",
       " 'uacute',\n",
       " 'finds',\n",
       " 'addicted',\n",
       " 'device',\n",
       " 'finds',\n",
       " 'slowly',\n",
       " 'restoring',\n",
       " 'youth',\n",
       " 'strength',\n",
       " 'party',\n",
       " 'also',\n",
       " 'finds',\n",
       " 'giving',\n",
       " 'hunger',\n",
       " 'wealthy',\n",
       " 'dying',\n",
       " 'businessman',\n",
       " 'determined',\n",
       " 'find',\n",
       " 'device',\n",
       " 'sends',\n",
       " 'brutal',\n",
       " 'nephew',\n",
       " 'angel',\n",
       " 'ron',\n",
       " 'perlman',\n",
       " 'find',\n",
       " 'angel',\n",
       " 'even',\n",
       " 'kills',\n",
       " 'jes',\n",
       " 'uacute',\n",
       " 'old',\n",
       " 'man',\n",
       " 'tell',\n",
       " 'wants',\n",
       " 'know',\n",
       " 'jes',\n",
       " 'uacute',\n",
       " 'rises',\n",
       " 'undead',\n",
       " 'creature',\n",
       " 'still',\n",
       " 'determined',\n",
       " 'get',\n",
       " 'device',\n",
       " 'back',\n",
       " 'young',\n",
       " 'granddaughter',\n",
       " 'danger',\n",
       " 'well',\n",
       " 'cronos',\n",
       " 'first',\n",
       " 'movie',\n",
       " 'guillermo',\n",
       " 'ever',\n",
       " 'directed',\n",
       " 'surprising',\n",
       " 'feels',\n",
       " 'little',\n",
       " 'rough',\n",
       " 'compared',\n",
       " 'later',\n",
       " 'work',\n",
       " 'expect',\n",
       " 'lots',\n",
       " 'del',\n",
       " 'toro',\n",
       " 'trademarks',\n",
       " 'mysterious',\n",
       " 'golden',\n",
       " 'items',\n",
       " 'insects',\n",
       " 'weird',\n",
       " 'grotesque',\n",
       " 'vampirism',\n",
       " 'religious',\n",
       " 'symbolism',\n",
       " 'favored',\n",
       " 'actors',\n",
       " 'luppi',\n",
       " 'entire',\n",
       " 'movie',\n",
       " 'beautifully',\n",
       " 'directed',\n",
       " 'del',\n",
       " 'toro',\n",
       " 'paints',\n",
       " 'every',\n",
       " 'scene',\n",
       " 'shadows',\n",
       " 'gold',\n",
       " 'blood',\n",
       " 'rather',\n",
       " 'going',\n",
       " 'spookery',\n",
       " 'del',\n",
       " 'toro',\n",
       " 'mingles',\n",
       " 'vampiric',\n",
       " 'horror',\n",
       " 'jesus',\n",
       " 'staring',\n",
       " 'hungrily',\n",
       " 'granddaughter',\n",
       " 'visceral',\n",
       " 'psychological',\n",
       " 'horror',\n",
       " 'jes',\n",
       " 'uacute',\n",
       " 'returns',\n",
       " 'life',\n",
       " 'mouth',\n",
       " 'stitched',\n",
       " 'shut',\n",
       " 'even',\n",
       " 'subtle',\n",
       " 'like',\n",
       " 'see',\n",
       " 'even',\n",
       " 'jes',\n",
       " 'uacute',\n",
       " 'flesh',\n",
       " 'turning',\n",
       " 'white',\n",
       " 'luppi',\n",
       " 'absolutely',\n",
       " 'brilliant',\n",
       " 'jes',\n",
       " 'uacute',\n",
       " 'starts',\n",
       " 'genial',\n",
       " 'kindly',\n",
       " 'old',\n",
       " 'man',\n",
       " 'love',\n",
       " 'antiques',\n",
       " 'slowly',\n",
       " 'eaten',\n",
       " 'away',\n",
       " 'lust',\n",
       " 'blood',\n",
       " 'addiction',\n",
       " 'device',\n",
       " 'end',\n",
       " 'movie',\n",
       " 'see',\n",
       " 'tiny',\n",
       " 'flicker',\n",
       " 'perlman',\n",
       " 'gives',\n",
       " 'similarly',\n",
       " 'awesome',\n",
       " 'performance',\n",
       " 'devious',\n",
       " 'thug',\n",
       " 'claudio',\n",
       " 'brook',\n",
       " 'great',\n",
       " 'dying',\n",
       " 'took',\n",
       " 'long',\n",
       " 'time',\n",
       " 'movie',\n",
       " 'finally',\n",
       " 'coming',\n",
       " 'criterion',\n",
       " 'catalog',\n",
       " 'restored',\n",
       " 'digital',\n",
       " 'transfer',\n",
       " 'del',\n",
       " 'toro',\n",
       " 'early',\n",
       " 'short',\n",
       " 'film',\n",
       " 'geometria',\n",
       " 'tour',\n",
       " 'de',\n",
       " 'toro',\n",
       " 'house',\n",
       " 'audio',\n",
       " 'commentaries',\n",
       " 'del',\n",
       " 'toro',\n",
       " 'producers',\n",
       " 'video',\n",
       " 'interviews',\n",
       " 'del',\n",
       " 'toro',\n",
       " 'luppi',\n",
       " 'navarro',\n",
       " 'perlman',\n",
       " 'stills',\n",
       " 'gallery',\n",
       " 'trailer',\n",
       " 'new',\n",
       " 'english',\n",
       " 'subtitles',\n",
       " 'booklet',\n",
       " 'maitland',\n",
       " 'mcdonagh',\n",
       " 'essay',\n",
       " 'del',\n",
       " 'toro',\n",
       " 'notes',\n",
       " 'cronos',\n",
       " 'little',\n",
       " 'guillermo',\n",
       " 'del',\n",
       " 'toro',\n",
       " 'later',\n",
       " 'work',\n",
       " 'still',\n",
       " 'powerful',\n",
       " 'haunting',\n",
       " 'horror',\n",
       " 'movie',\n",
       " 'absolute']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "text_process(X['Text'].to_numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer(analyzer=text_process, max_features=2000)\n",
    "# vocab = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "svc = SVC(C=1, class_weight='balanced', gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing Tf-idf, total= 7.4min\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 3.9min\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Tf-idf',\n",
       "                 TfidfVectorizer(analyzer=<function text_process at 0x0000022A0C3F8430>,\n",
       "                                 max_features=25000)),\n",
       "                ('classifier', SVC(C=1, class_weight='balanced'))],\n",
       "         verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "pipeline = Pipeline([('Tf-idf', TfidfVectorizer(analyzer=text_process, max_features=25000)), ('classifier', svc)], verbose=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.15)\n",
    "pipeline.fit(x_train['Text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionSet = pd.read_csv(\"./data/prediction.csv\")\n",
    "# predictionSet = predictionSet[predictionSet['Summary'].notnull()]\n",
    "predictionSet['Text'].fillna(\"na\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = predictionSet['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
       "0             5  0005019281  A2L0G56BNOTX6S                     0   \n",
       "1            11  0005019281  A33EWPXESP9GQH                     0   \n",
       "2            17  0005019281  A13KAQO9F5X0FN                     0   \n",
       "3            46  0005019281  A306NASGVUDFKF                    10   \n",
       "4            47  0005019281  A38G1NN5SD81GD                     0   \n",
       "...         ...         ...             ...                   ...   \n",
       "299995  1697520  B00LH9ROKM   AYB0IXBPBJ20A                     0   \n",
       "299996  1697522  B00LT1JHLW   AU73NIGESSIRE                    25   \n",
       "299997  1697524  B00LT1JHLW  A3PPYOJBMFBP6U                     3   \n",
       "299998  1697527  B00LT1JHLW  A2CA2Q6JS6CQAE                    10   \n",
       "299999  1697528  B00LT1JHLW   AV657BUYHHXZ2                     1   \n",
       "\n",
       "        HelpfulnessDenominator        Time  \\\n",
       "0                            0  1383696000   \n",
       "1                            0  1390780800   \n",
       "2                            0  1389657600   \n",
       "3                           14  1132963200   \n",
       "4                            1  1384905600   \n",
       "...                        ...         ...   \n",
       "299995                       1  1404345600   \n",
       "299996                      88  1405555200   \n",
       "299997                      10  1405728000   \n",
       "299998                      14  1405987200   \n",
       "299999                      14  1406073600   \n",
       "\n",
       "                                                  Summary  \\\n",
       "0                                        Dickens updated.   \n",
       "1                                            Good Version   \n",
       "2                                   the fonz does scrooge   \n",
       "3                 A refreshing twist on a Holiday classic   \n",
       "4                                         Not my favorite   \n",
       "...                                                   ...   \n",
       "299995  Basically an Episode of Criminal Minds, See It...   \n",
       "299996  July 17, 2014 - the first day of pre-order (wi...   \n",
       "299997  Please Include The 'Batman In Color' Bumper Wh...   \n",
       "299998    Finally on dvd and blu-ray The Batman TV Series   \n",
       "299999                      Way to Expensive!! WB = GREED   \n",
       "\n",
       "                                                     Text  Score  \n",
       "0       This has been a favorite movie of mine for a l...    5.0  \n",
       "1       Even though i don't care for Henry Winklers  a...    3.0  \n",
       "2       Anorher good movie for holiday watchers..a lit...    4.0  \n",
       "3       My wife and I grew up in New Hampshire where t...    5.0  \n",
       "4       This is a first for me, I didn't like this mov...    2.0  \n",
       "...                                                   ...    ...  \n",
       "299995  Just how seriously one should take Scott Derri...    4.0  \n",
       "299996  Let's be clear - the 5 stars are for the serie...    5.0  \n",
       "299997  I would also like to see the original 20th Cen...    1.0  \n",
       "299998  Finally to be released on DVD and Blu-Ray Nove...    5.0  \n",
       "299999  wow $269.99 for the entire series on Blu Ray??...    5.0  \n",
       "\n",
       "[300000 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>0005019281</td>\n      <td>A2L0G56BNOTX6S</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1383696000</td>\n      <td>Dickens updated.</td>\n      <td>This has been a favorite movie of mine for a l...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11</td>\n      <td>0005019281</td>\n      <td>A33EWPXESP9GQH</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1390780800</td>\n      <td>Good Version</td>\n      <td>Even though i don't care for Henry Winklers  a...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17</td>\n      <td>0005019281</td>\n      <td>A13KAQO9F5X0FN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1389657600</td>\n      <td>the fonz does scrooge</td>\n      <td>Anorher good movie for holiday watchers..a lit...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>46</td>\n      <td>0005019281</td>\n      <td>A306NASGVUDFKF</td>\n      <td>10</td>\n      <td>14</td>\n      <td>1132963200</td>\n      <td>A refreshing twist on a Holiday classic</td>\n      <td>My wife and I grew up in New Hampshire where t...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47</td>\n      <td>0005019281</td>\n      <td>A38G1NN5SD81GD</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1384905600</td>\n      <td>Not my favorite</td>\n      <td>This is a first for me, I didn't like this mov...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>1697520</td>\n      <td>B00LH9ROKM</td>\n      <td>AYB0IXBPBJ20A</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1404345600</td>\n      <td>Basically an Episode of Criminal Minds, See It...</td>\n      <td>Just how seriously one should take Scott Derri...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>1697522</td>\n      <td>B00LT1JHLW</td>\n      <td>AU73NIGESSIRE</td>\n      <td>25</td>\n      <td>88</td>\n      <td>1405555200</td>\n      <td>July 17, 2014 - the first day of pre-order (wi...</td>\n      <td>Let's be clear - the 5 stars are for the serie...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>1697524</td>\n      <td>B00LT1JHLW</td>\n      <td>A3PPYOJBMFBP6U</td>\n      <td>3</td>\n      <td>10</td>\n      <td>1405728000</td>\n      <td>Please Include The 'Batman In Color' Bumper Wh...</td>\n      <td>I would also like to see the original 20th Cen...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>1697527</td>\n      <td>B00LT1JHLW</td>\n      <td>A2CA2Q6JS6CQAE</td>\n      <td>10</td>\n      <td>14</td>\n      <td>1405987200</td>\n      <td>Finally on dvd and blu-ray The Batman TV Series</td>\n      <td>Finally to be released on DVD and Blu-Ray Nove...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>1697528</td>\n      <td>B00LT1JHLW</td>\n      <td>AV657BUYHHXZ2</td>\n      <td>1</td>\n      <td>14</td>\n      <td>1406073600</td>\n      <td>Way to Expensive!! WB = GREED</td>\n      <td>wow $269.99 for the entire series on Blu Ray??...</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "predictionSet['Score'] = pipeline.predict(x_predict)\n",
    "# x_test['Score'] = pipeline.predict(x_test['Text'])\n",
    "# x_test = x_test.sort_values(by=['Id'])\n",
    "# x_test\n",
    "predictionSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = predictionSet[['Id', 'Score']]\n",
    "# submission_offline = x_test[['Id', 'Score']]\n",
    "# print(submission_offline.head())\n",
    "submission.to_csv(\"./data/submission.csv\", index=False)\n",
    "# submission_offline.to_csv(\"./data/submission_offline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}